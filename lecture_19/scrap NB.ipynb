{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(quote):\n",
    "    quoteText = quote.select_one(\"div.quoteText\")\n",
    "    text = quoteText.text.split(\"\\n\")\n",
    "    author = text[-3].strip()\n",
    "    quote_text = text[1].strip()\n",
    "    \n",
    "    footer = quote.select_one(\"div.quoteFooter\")\n",
    "    tags_list = footer.select_one(\"div.greyText\")\n",
    "    tags = []\n",
    "    if tags_list:\n",
    "        for tag in tags_list.find_all(\"a\"):\n",
    "            tags.append(tag.text)\n",
    "    \n",
    "    deatails = {}\n",
    "    deatails[\"author\"] = author\n",
    "    deatails[\"quote\"] = quote_text\n",
    "    deatails[\"tags\"] = tags\n",
    "    \n",
    "    return deatails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab(url):\n",
    "    data = requests.get(url).text\n",
    "    soup = BeautifulSoup(data)\n",
    "    quotes_data = soup.find_all(\"div\", attrs={\"class\" : \"quote\"})\n",
    "    quotes = []\n",
    "    \n",
    "    for q in quotes_data:\n",
    "        quotes.append(gen_data(q))\n",
    "    \n",
    "    return quotes\n",
    "# gen_data(quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\"love\", \"humor\", \"education\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapping page 1\n",
      "scrapping page 2\n",
      "scrapping page 3\n",
      "scrapping page 1\n",
      "scrapping page 2\n",
      "scrapping page 3\n",
      "scrapping page 1\n",
      "scrapping page 2\n",
      "scrapping page 3\n"
     ]
    }
   ],
   "source": [
    "base = \"https://www.goodreads.com/quotes/tag/{0}?page={1}\"\n",
    "\n",
    "for e in emotions:\n",
    "    all_quotes = []\n",
    "    for i in range(1, 4):\n",
    "        print(\"scrapping page \" + str(i))\n",
    "        all_quotes += grab(base.format(e, str(i)))\n",
    "    json.dump(all_quotes, open(e+\".json\", \"w\", encoding=\"utf16\"))  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for index, e in enumerate(emotions):\n",
    "    quotes = json.load(open(e + \".json\", \"r\", encoding=\"utf16\"))\n",
    "    lines = [q[\"quote\"][1:-1] for q in quotes]\n",
    "    X += lines\n",
    "    y += [index]*len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(stopwords.words(\"english\"))\n",
    "punc = set(string.punctuation)\n",
    "useless = sw.union(punc)\n",
    "\n",
    "pts = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mytokenizer(line):\n",
    "    words = word_tokenize(line.lower())\n",
    "    usefull = [w for w in words if w not in useless]\n",
    "    res = [pts.stem(w) for w in usefull]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(tokenizer=mytokenizer, ngram_range=(1, 2), min_df=.007, max_df=.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = cv.fit_transform(X)\n",
    "\n",
    "vals = vec.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "676"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(vals, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5222222222222223"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
